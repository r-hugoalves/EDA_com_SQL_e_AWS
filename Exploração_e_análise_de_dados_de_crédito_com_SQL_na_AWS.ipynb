{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzCkjlNq+yjlnBLilJ89oU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-hugoalves/EDA_com_SQL_e_AWS/blob/master/Explora%C3%A7%C3%A3o_e_an%C3%A1lise_de_dados_de_cr%C3%A9dito_com_SQL_na_AWS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploração e análise de dados de crédito com SQL na AWS**"
      ],
      "metadata": {
        "id": "rhfWKC2D405E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nesse estudo, vamos analisar um conjunto de dados que representam informações de clientes de um banco.**"
      ],
      "metadata": {
        "id": "_gnNct2645NL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o nosso estudo, vamos utilizar as ferramentas S3 e Athena da AWS e uma parte do conjunto de dados disponibilizados [nesse](https://github.com/andre-marcos-perez/ebac-course-utils/tree/main/dataset) repositório*. Além disso, todos os gráficos aqui apresentados foram gerados utilizando o excel.\n",
        "\n",
        "O conjunto em específico que vamos utilizar pode ser obtido [aqui](https://github.com/r-hugoalves/EDA_com_SQL_e_AWS/blob/master/planilha_geral.csv).\n",
        "\n",
        "<br>\n",
        "\n",
        "**.: não vamos trabalhar com todo o conjunto de dados para não ultrapassar o período gratuito da AWS. Por isso, utilizaremos apenas as 2563 primeiras linhas.*"
      ],
      "metadata": {
        "id": "svJ6TM4b45KI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dados"
      ],
      "metadata": {
        "id": "8L1_A4w045F3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Legenda dos dados presentes na tabela:\n",
        "\n",
        "* idade = idade do cliente\n",
        "* sexo = sexo do cliente (F ou M)\n",
        "* dependentes = número de dependentes do cliente\n",
        "* escolaridade = nível de escolaridade do clientes\n",
        "* salario_anual = faixa salarial do cliente\n",
        "* tipo_cartao = tipo de cartao do cliente\n",
        "* qtd_produtos = quantidade de produtos comprados nos últimos 12 meses\n",
        "* iteracoes_12m = quantidade de iterações/transacoes nos ultimos 12 meses\n",
        "* meses_inativo_12m = quantidade de meses que o cliente ficou inativo\n",
        "* limite_credito = limite de credito do cliente\n",
        "* valor_transacoes_12m = valor das transações dos ultimos 12 meses\n",
        "* qtd_transacoes_12m = quantidade de transacoes dos ultimos 12 meses"
      ],
      "metadata": {
        "id": "tsxpdvkO45BL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extração dos dados"
      ],
      "metadata": {
        "id": "v9oxXkGj447H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os dados obtidos no repositório original contém mais de 10mil linhas. Porém, para não extrapolar o limite dos serviços gratuitos da AWS vamos trabalhar com apenas 2563 linhas. \n",
        "\n",
        "Mas temos que tomar alguns cuidados! Quando exportarmos o arquivo seja no formato `xlsx` ou `csv`, existem duas colunas em específico que pode causar erro ao fazermos o upload no S3. \n",
        "\n",
        "São as colunas `limite_credito` e `valor_transacoes_12m` do nosso arquivo. Como ambas as colunas tratam de dados do tipo float, devemos substituir a vírgula por ponto antes de subir no S3, caso contrário, ele pode ler a vírgula e separar as informações de forma incorreta quando criarmos a nossa tabela no Athena. Essa substituição foi feita de forma direta e simples no próprio Excel.\n",
        "\n",
        "Após isso, foi feito o upload no S3 e criação da tabela no Athena, conforme detalhado abaixo."
      ],
      "metadata": {
        "id": "PpLUo1rlBTiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação da tabela"
      ],
      "metadata": {
        "id": "Fbij9hKJCyhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a criação do bucket no S3, foi criada a tabela `credito` no Athena:"
      ],
      "metadata": {
        "id": "tFzY3iN6Dwuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` sql\n",
        "CREATE EXTERNAL TABLE IF NOT EXISTS default.credito(\n",
        "   `idade` int,\n",
        "   `sexo` string,\n",
        "   `dependentes` int,\n",
        "   `escolaridade` string,\n",
        "   `estado_civil` string,\n",
        "   `salario_anual` string,\n",
        "   `tipo_cartao` string,\n",
        "   `qtd_produtos` bigint,\n",
        "   `iteracoes_12m` int,\n",
        "   `meses_inativo_12m` int,\n",
        "   `limite_credito` float,\n",
        "   `valor_transacoes_12m` float,\n",
        "   `qtd_transacoes_12m` int\n",
        ")\n",
        "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
        "WITH SERDEPROPERTIES(\n",
        "    'serialization.format' = ',',\n",
        "    'field.delim' = ','\n",
        ") LOCATION 's3://proj-credito-hra/'\n",
        "TBLPROPERTIES ('has_encrypted_data'='false');\n",
        "```"
      ],
      "metadata": {
        "id": "VXjwP_tsC0Ja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploração dos dados"
      ],
      "metadata": {
        "id": "jPqPIOcO6hzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise dos dados"
      ],
      "metadata": {
        "id": "7E1mbNjk6hvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão"
      ],
      "metadata": {
        "id": "5entwvyT6ho3"
      }
    }
  ]
}